

# 安装kubernetes组件

## 生成集群CA证书




## 部署MASTER

#### https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG
#### 下载地址 https://dl.k8s.io/v1.22.8/kubernetes-server-linux-amd64.tar.gz

1.上传kubernetes-server-linux-amd64.tar.gz包并解压，如还有其他master节点，则也拷贝到其他节点上

~~~powershell
[root@master software]# tar zxf kubernetes-server-linux-amd64.tar.gz
[root@master software]# ll
total 534836
-rw-r--r-- 1 root root   9565743 Dec 20 17:40 flannel-v0.11.0-linux-amd64.tar.gz
drwxr-xr-x 4 root root        79 Aug 19 19:30 kubernetes
-rw-r--r-- 1 root root  94257559 Dec 20 17:40 kubernetes-node-linux-amd64.tar.gz
-rw-r--r-- 1 root root 443841740 Dec 20 17:40 kubernetes-server-linux-amd64.tar.gz
[root@master software]# cp -r kubernetes/server /data/apps/kubernetes/

拷贝kubernetes-node-linux-amd64.tar.gz到node节点
scp kubernetes-node-linux-amd64.tar.gz 192.168.0.21:/root
scp kubernetes-node-linux-amd64.tar.gz 192.168.0.22:/root
~~~

2.配置环境变量，安装docker命令补全

~~~powershell
# yum install bash-completion -y
# cat > /etc/profile.d/kubernetes.sh << EOF
K8S_HOME=/data/apps/kubernetes
export PATH=\$K8S_HOME/server/bin:\$PATH
source <(kubectl completion bash)
EOF
# source /etc/profile.d/kubernetes.sh
# kubectl version
~~~

3.配置TLS Bootstrapping

配置有问题时候会导致 kubectl get csr 显示No Resources Found
https://blog.csdn.net/weixin_33695082/article/details/91672619

~~~powershell
# export BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d ' ')
# cat > /data/apps/kubernetes/token.csv << EOF
${BOOTSTRAP_TOKEN},kubelet-bootstrap,10001,"system:kubelet-bootstrap"
EOF
~~~

4.创建 kubelet bootstrapping kubeconfig

设置 kube-apiserver 访问地址， 如果需要对 kube-apiserver 配置高可用集群， 则这里设置apiserver 浮动 IP。  KUBE_APISERVER=浮动 IP，如果是单节点，则直接配置ip即可

~~~powershell
[root@master kubernetes]# cd /data/apps/kubernetes/

[root@master kubernetes]# export KUBE_APISERVER="https://192.168.10.162:6443"

# 设置集群参数
[root@master kubernetes]# kubectl config set-cluster kubernetes \
--certificate-authority=/data/apps/kubernetes/pki/ca.pem \
--embed-certs=true \
--server=${KUBE_APISERVER} \
--kubeconfig=kubelet-bootstrap.kubeconfig

# 设置客户端认证参数
[root@master kubernetes]# kubectl config set-credentials kubelet-bootstrap \
--token=${BOOTSTRAP_TOKEN} \
--kubeconfig=kubelet-bootstrap.kubeconfig

# 置上下文参数
[root@master kubernetes]# kubectl config set-context default \
--cluster=kubernetes \
--user=kubelet-bootstrap \
--kubeconfig=kubelet-bootstrap.kubeconfig

# 设置默认上下文
[root@master kubernetes]# kubectl config use-context default --kubeconfig=kubelet-bootstrap.kubeconfig

~~~

5.创建 kube-controller-manager kubeconfig

~~~powershell
[root@master kubernetes]# kubectl config set-cluster kubernetes \
--certificate-authority=/data/apps/kubernetes/pki/ca.pem \
--embed-certs=true \
--server=${KUBE_APISERVER} \
--kubeconfig=kube-controller-manager.kubeconfig

[root@master kubernetes]# kubectl config set-credentials kube-controller-manager \
--client-certificate=/data/apps/kubernetes/pki/kube-controller-manager.pem \
--client-key=/data/apps/kubernetes/pki/kube-controller-manager-key.pem \
--embed-certs=true \
--kubeconfig=kube-controller-manager.kubeconfig

[root@master kubernetes]# kubectl config set-context default \
--cluster=kubernetes \
--user=kube-controller-manager \
--kubeconfig=kube-controller-manager.kubeconfig

[root@master kubernetes]# kubectl config use-context default --kubeconfig=kube-controller-manager.kubeconfig
~~~

6.创建 kube-scheduler kubeconfig

~~~powershell
[root@master kubernetes]# kubectl config set-cluster kubernetes \
--certificate-authority=/data/apps/kubernetes/pki/ca.pem \
--embed-certs=true \
--server=${KUBE_APISERVER} \
--kubeconfig=kube-scheduler.kubeconfig

[root@master kubernetes]# kubectl config set-credentials kube-scheduler \
--client-certificate=/data/apps/kubernetes/pki/kube-scheduler.pem \
--client-key=/data/apps/kubernetes/pki/kube-scheduler-key.pem \
--embed-certs=true \
--kubeconfig=kube-scheduler.kubeconfig

[root@master kubernetes]# kubectl config set-context default \
--cluster=kubernetes \
--user=kube-scheduler \
--kubeconfig=kube-scheduler.kubeconfig

[root@master kubernetes]# kubectl config use-context default --kubeconfig=kube-scheduler.kubeconfig
~~~

7.创建 kube-proxy kubeconfig

~~~powershell
[root@master kubernetes]# kubectl config set-cluster kubernetes \
--certificate-authority=/data/apps/kubernetes/pki/ca.pem \
--embed-certs=true \
--server=${KUBE_APISERVER} \
--kubeconfig=kube-proxy.kubeconfig

[root@master kubernetes]# kubectl config set-credentials kube-proxy \
--client-certificate=/data/apps/kubernetes/pki/kube-proxy.pem \
--client-key=/data/apps/kubernetes/pki/kube-proxy-key.pem \
--embed-certs=true \
--kubeconfig=kube-proxy.kubeconfig

[root@master kubernetes]# kubectl config set-context default \
--cluster=kubernetes \
--user=kube-proxy \
--kubeconfig=kube-proxy.kubeconfig

[root@master kubernetes]# kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig
~~~

8.创建 admin kubeconfig

~~~powershell
[root@master kubernetes]# kubectl config set-cluster kubernetes \
--certificate-authority=/data/apps/kubernetes/pki/ca.pem \
--embed-certs=true \
--server=${KUBE_APISERVER} \
--kubeconfig=admin.conf

[root@master kubernetes]# kubectl config set-credentials admin \
--client-certificate=/data/apps/kubernetes/pki/admin.pem \
--client-key=/data/apps/kubernetes/pki/admin-key.pem \
--embed-certs=true \
--kubeconfig=admin.conf

[root@master kubernetes]# kubectl config set-context default \
--cluster=kubernetes \
--user=admin \
--kubeconfig=admin.conf

[root@master kubernetes]# kubectl config use-context default --kubeconfig=admin.conf
~~~

9.分发 kubelet/kube-proxy 配置文件

9.1分发配置文件到 node 节点

~~~powershell
[root@master kubernetes]# mv kube* token.csv admin.conf etc/
[root@master kubernetes]# rsync -avz --exclude=kube-scheduler.kubeconfig --exclude=kube-controller-manager.kubeconfig --exclude=admin.conf --exclude=token.csv etc 192.168.10.190:/data/apps/kubernetes

[root@master kubernetes]# rsync -avz --exclude=kube-scheduler.kubeconfig --exclude=kube-controller-manager.kubeconfig --exclude=admin.conf --exclude=token.csv etc 192.168.10.191:/data/apps/kubernetes
~~~



9.2分发配置文件到其他 master 节点

......

10.配置 kube-apiserver

~~~powershell
# cd /data/apps/kubernetes/pki/
# openssl genrsa -out /data/apps/kubernetes/pki/sa.key 2048
# openssl rsa -in /data/apps/kubernetes/pki/sa.key -pubout -out /data/apps/kubernetes/pki/sa.pub
~~~

分发文件到其他apiserver节点(没有则省略)

~~~powershell
scp -r /data/apps/kubernetes/pki/sa.* *.*.*.*:/data/apps/kubernetes/pki/
scp -r /data/apps/kubernetes/etc *.*.*.*:/data/apps/kubernetes/

~~~

11 配置 apiserver 系统服务



11.1 配置文件

~~~powershell
# cat > /data/apps/kubernetes/etc/kube-apiserver.conf << EOF
KUBE_APISERVER_OPTS="--enable-admission-plugins=NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \
  --anonymous-auth=false \
  --bind-address=192.168.10.162 \
  --secure-port=6443 \
  --advertise-address=192.168.10.162 \
  --insecure-port=0 \
  --authorization-mode=Node,RBAC \
  --enable-bootstrap-token-auth \
  --service-cluster-ip-range=10.99.0.0/16 \
  --token-auth-file=/data/apps/kubernetes/etc/token.csv \
  --service-node-port-range=30000-50000 \
  --tls-cert-file=/data/apps/kubernetes/pki/kube-apiserver.pem  \
  --tls-private-key-file=/data/apps/kubernetes/pki/kube-apiserver-key.pem \
  --client-ca-file=/data/apps/kubernetes/pki/ca.pem \
  --kubelet-client-certificate=/data/apps/kubernetes/pki/admin.pem \
  --kubelet-client-key=/data/apps/kubernetes/pki/admin-key.pem \
  --service-account-key-file=/data/apps/kubernetes/pki/ca.pem \
  --service-account-signing-key-file=/data/apps/kubernetes/pki/ca-key.pem  \
  --service-account-issuer=https://kubernetes.default.svc.cluster.local \
  --etcd-cafile=/data/apps/etcd/ssl/etcd-ca.pem \
  --etcd-certfile=/data/apps/etcd/ssl/etcd.pem \
  --etcd-keyfile=/data/apps/etcd/ssl/etcd-key.pem \
  --etcd-servers=https://192.168.10.162:2379,https://192.168.10.190:2379,https://192.168.10.191:2379 \
  --enable-swagger-ui=true \
  --allow-privileged=true \
  --apiserver-count=1 \
  --audit-log-maxage=30 \
  --audit-log-maxbackup=3 \
  --audit-log-maxsize=100 \
  --audit-log-path=/data/apps/kubernetes/log/kubernetes.audit \
  --event-ttl=12h \
  --alsologtostderr=true \
  --logtostderr=false \
  --log-dir=/data/apps/kubernetes/log/apiserver \
  --runtime-config=api/all=true \
  --requestheader-allowed-names=aggregator \
  --requestheader-group-headers=X-Remote-Group \
  --requestheader-username-headers=X-Remote-User \
  --requestheader-extra-headers-prefix=X-Remote-Extra- \
  --requestheader-client-ca-file=/data/apps/kubernetes/pki/ca.pem \
  --proxy-client-cert-file=/data/apps/kubernetes/pki/proxy-client.pem \
  --proxy-client-key-file=/data/apps/kubernetes/pki/proxy-client-key.pem \
  --v=4 "
EOF
service-account-key-file=/data/apps/kubernetes/pki/sa.pub 
使用该文件controller-manager一直无权限，先改为ca.pem 同时controller-manager 要同步修改
--tls-cert-file=/data/apps/kubernetes/pki/kube-apiserver.pem  
--tls-private-key-file=/data/apps/kubernetes/pki/kube-apiserver-key.pem
作为服务器端，必须要准备好自己的证书(对)，所以这两个参数就是指定了证书的路径。
--client-ca-file
这个参数的含义是指定客户端使用的根证书的路径。一旦设置了，那么你在访问api的时候一定得带上使用该根证书签发的公钥/私钥对
--service-account-key-file
该参数表示的含义是公钥的路径，它与kube-controller-manager的--service-account-private-key-file是对应关系，因为pod带着token去访问api server，则api server要能解密才行，所以同时还需要在api那里配置，当然如果不配置，不影响pod创建，只不过在pod里访问api的时候就不行了。
~~~
11.2 系统服务文件

~~~powershell
# cat > /usr/lib/systemd/system/kube-apiserver.service << EOF
[Unit]
Description=Kubernetes API Service
Documentation=https://github.com/kubernetes/kubernetes
After=network.target
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kube-apiserver.conf
ExecStart=/data/apps/kubernetes/server/bin/kube-apiserver \\
\$KUBE_APISERVER_OPTS 
Restart=on-failure
Type=notify
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
EOF
~~~
11.3 启动所有apiserver

~~~powershell
# systemctl daemon-reload
# systemctl enable kube-apiserver
# systemctl restart kube-apiserver
# systemctl status kube-apiserver


注意：启动时会出错，Error: enable-admission-plugins plugin "Initializers" is unknown
所以删除了--enable-admission-plugins=Initializers

# 测试是否可以访问
# curl -k https://192.168.10.162:6443
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "Failure",
  "message": "Unauthorized",
  "reason": "Unauthorized",
  "code": 401
}
~~~

12 配置启动 kube-controller-manager

kube-controller-manager  负责维护集群的状态，比如故障检测、自动扩展、滚动更新等
在启动时设置  --leader-elect=true 后， controller manager 会使用多节点选主的方式选择主节点。只有主节点才会调用  StartControllers() 启动所有控制器，而其他从节点则仅执行选主算法。

~~~powershell
# 创建系统服务文件
# cat > /usr/lib/systemd/system/kube-controller-manager.service << EOF
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kube-controller-manager.conf
ExecStart=/data/apps/kubernetes/server/bin/kube-controller-manager \$KUBE_CONTROLLER_MANAGER_OPTS
Restart=always
RestartSec=10s
#Restart=on-failure
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
EOF

# 创建配置文件 启动报错 请仔细查询日志 journalctl -xeu kube-controller-manager
# cat > /data/apps/kubernetes/etc/kube-controller-manager.conf << EOF
KUBE_CONTROLLER_MANAGER_OPTS="--kubeconfig=/data/apps/kubernetes/etc/kube-controller-manager.kubeconfig \\
  --authentication-kubeconfig=/data/apps/kubernetes/etc/kube-controller-manager.kubeconfig \\
  --allocate-node-cidrs=true \\
  --service-cluster-ip-range=10.99.0.0/16 \\
  --cluster-name=kubernetes \\
  --cluster-signing-cert-file=/data/apps/kubernetes/pki/ca.pem \\
  --cluster-signing-key-file=/data/apps/kubernetes/pki/ca-key.pem \\
  --cluster-cidr=10.88.0.0/16 \\
  --cluster-signing-duration=87600h \\
  --root-ca-file=/data/apps/kubernetes/pki/ca.pem \\
  --service-account-private-key-file=/data/apps/kubernetes/pki/ca-key.pem \\
  --leader-elect=true \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --controllers=*,bootstrapsigner,tokencleaner \\
  --tls-cert-file=/data/apps/kubernetes/pki/kube-controller-manager.pem \\
  --tls-private-key-file=/data/apps/kubernetes/pki/kube-controller-manager-key.pem \\
  --use-service-account-credentials=true \\
  --alsologtostderr=true \\
  --logtostderr=false \\
  --log-dir=/data/apps/kubernetes/log/controller-manager \\
  --v=2"
EOF

--service-account-private-key-file
该参数表示的含义是私钥的路径，它的作用是给服务账号产生token，之后pod就可以拿着这个token去访问api server了。

--root-ca-file
该参数会给服务账号一个根证书ca.pem，可选配置，如果配置成给api server签发证书的那个根证书，那就可以拿来用于认证api server。

# 启动 kube-controller-manager
# systemctl daemon-reload
# systemctl enable kube-controller-manager
# systemctl start kube-controller-manager
# systemctl status kube-controller-manager

~~~

13.配置kubectl

~~~powershell
# rm -rf $HOME/.kube
# mkdir -p $HOME/.kube
# cp /data/apps/kubernetes/etc/admin.conf $HOME/.kube/config
# sudo chown $(id -u):$(id -g) $HOME/.kube/config
# kubectl get node
# kubectl get componentstatuses

~~~

14.配置kubelet 使用 bootstrap

~~~powershell
# kubectl delete clusterrolebinding kubelet-bootstrap 
 
# kubectl create clusterrolebinding kubelet-bootstrap \
--clusterrole=system:node-bootstrapper \
--user=kubelet-bootstrap
~~~

15.配置启动 kube-scheduler

kube-scheduler 负责分配调度 Pod 到集群内的节点上，它监听 kube-apiserver，查询还未分配 Node 的 Pod，然后根据调度策略为这些 Pod 分配节点。按照预定的调度策略将Pod 调度到相应的机器上（更新 Pod 的NodeName 字段）。

~~~powershell
# 创建系统服务文件
# cat > /usr/lib/systemd/system/kube-scheduler.service << EOF
[Unit]
Description=Kubernetes Scheduler Plugin
Documentation=https://github.com/kubernetes/kubernetes
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kube-scheduler.conf
ExecStart=/data/apps/kubernetes/server/bin/kube-scheduler \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBECONFIG \\
\$KUBE_SCHEDULER_ARGS
Restart=on-failure
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
EOF


# 创建 kube-scheduler.conf 配置文件
# cat > /data/apps/kubernetes/etc/kube-scheduler.conf<< EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/scheduler"
KUBECONFIG="--kubeconfig=/data/apps/kubernetes/etc/kube-scheduler.kubeconfig"
KUBE_SCHEDULER_ARGS="--address=127.0.0.1"
EOF

# 启动 kube-scheduler， 并设置服务开机自启动
# systemctl daemon-reload
# systemctl enable kube-scheduler
# systemctl restart kube-scheduler
# systemctl status kube-scheduler
~~~



## 部署Node

1. 配置 kubelet

kubelet 负责维持容器的生命周期，同时也负责 Volume（CVI）和网络（CNI）的管理；每个节点上都运行一个 kubelet 服务进程，默认监听 10250 端口，接收并执行 master 发来的指令，管理 Pod 及 Pod 中的容器。每个 kubelet 进程会在 API Server 上注册节点自身信息，定期向 master 节点汇报节点的资源使用情况，并通过 cAdvisor/metric-server 监控节点和容器的资源。

配置并启动 kubelet， flanneld (master 与 node 节点都需要安装)
在 ==Master 节点==配置 kubelet

~~~powershell
# 创建服务文件
# cat > /usr/lib/systemd/system/kubelet.service << EOF
[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kubelet.conf
ExecStart=/data/apps/kubernetes/server/bin/kubelet \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBELET_CONFIG \\
\$KUBELET_HOSTNAME \\
\$KUBELET_POD_INFRA_CONTAINER \\
\$KUBELET_ARGS
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF
# 创建 kubelet 配置文件
# cat > /data/apps/kubernetes/etc/kubelet.conf << EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/kubelet"
KUBELET_HOSTNAME="--hostname-override=192.168.10.162"
KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.2"
KUBELET_CONFIG="--config=/data/apps/kubernetes/etc/kubelet-config.yml"
KUBELET_ARGS="--bootstrap-kubeconfig=/data/apps/kubernetes/etc/kubelet-bootstrap.kubeconfig --kubeconfig=/data/apps/kubernetes/etc/kubelet.kubeconfig --cert-dir=/data/apps/kubernetes/pki"
EOF

注意kubelet.kubeconfig该文件，没有生成

# cat > /data/apps/kubernetes/etc/kubelet-config.yml << EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
address: 192.168.10.162
port: 10250
cgroupDriver: cgroupfs
clusterDNS:
- 10.99.0.2
clusterDomain: cluster.local.
hairpinMode: promiscuous-bridge
maxPods: 200
failSwapOn: false
imageGCHighThresholdPercent: 90
imageGCLowThresholdPercent: 80
imageMinimumGCAge: 5m0s
serializeImagePulls: false
featureGates: 
  RotateKubeletServerCertificate: true  
authentication:
  x509:
    clientCAFile: /data/apps/kubernetes/pki/ca.pem
  anonymous:
    enbaled: false
  webhook:
    enbaled: false
EOF
~~~

在Node1节点上配置 kubelet

~~~powershell
# cd /opt/software
# tar zxf kubernetes-node-linux-amd64.tar.gz
# mv kubernetes/node /data/apps/kubernetes/

# 系统服务文件
# cat > /usr/lib/systemd/system/kubelet.service << EOF
[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kubelet.conf
ExecStart=/data/apps/kubernetes/node/bin/kubelet \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBELET_CONFIG \\
\$KUBELET_HOSTNAME \\
\$KUBELET_POD_INFRA_CONTAINER \\
\$KUBELET_ARGS
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF

# 配置文件
# cat > /data/apps/kubernetes/etc/kubelet.conf << EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/kubelet/"
KUBELET_HOSTNAME="--hostname-override=192.168.10.190"
KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.2"
KUBELET_CONFIG="--config=/data/apps/kubernetes/etc/kubelet-config.yml"
KUBELET_ARGS="--bootstrap-kubeconfig=/data/apps/kubernetes/etc/kubelet-bootstrap.kubeconfig --kubeconfig=/data/apps/kubernetes/etc/kubelet.kubeconfig --cert-dir=/data/apps/kubernetes/pki"
EOF

# cat > /data/apps/kubernetes/etc/kubelet-config.yml << EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
address: 192.168.10.190
port: 10250
cgroupDriver: cgroupfs
clusterDNS:
  - 10.99.0.2
clusterDomain: cluster.local.
hairpinMode: promiscuous-bridge
maxPods: 200
failSwapOn: false
imageGCHighThresholdPercent: 90
imageGCLowThresholdPercent: 80
imageMinimumGCAge: 5m0s
serializeImagePulls: false
authentication:
  x509:
    clientCAFile: /data/apps/kubernetes/pki/ca.pem
  anonymous:
    enbaled: false
  webhook:
    enbaled: false
EOF

~~~

# node1启动kubelet
# systemctl daemon-reload
# systemctl enable kubelet
# systemctl restart kubelet
# systemctl status kubelet
~~~

在Node2节点上配置 kubelet

~~~powershell
# cd /opt/software
# tar zxf kubernetes-node-linux-amd64.tar.gz
# mv kubernetes/node /data/apps/kubernetes/

# 系统服务文件
# cat > /usr/lib/systemd/system/kubelet.service << EOF
[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kubelet.conf
ExecStart=/data/apps/kubernetes/node/bin/kubelet \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBELET_CONFIG \\
\$KUBELET_HOSTNAME \\
\$KUBELET_POD_INFRA_CONTAINER \\
\$KUBELET_ARGS
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF

# 配置文件
# cat > /data/apps/kubernetes/etc/kubelet.conf << EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/kubelet/"
KUBELET_HOSTNAME="--hostname-override=192.168.10.191"
KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.2"
KUBELET_CONFIG="--config=/data/apps/kubernetes/etc/kubelet-config.yml"
KUBELET_ARGS="--bootstrap-kubeconfig=/data/apps/kubernetes/etc/kubelet-bootstrap.kubeconfig --kubeconfig=/data/apps/kubernetes/etc/kubelet.kubeconfig --cert-dir=/data/apps/kubernetes/pki"
EOF

# cat > /data/apps/kubernetes/etc/kubelet-config.yml << EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
address: 192.168.10.191
port: 10250
cgroupDriver: cgroupfs
clusterDNS:
  - 10.99.0.2
clusterDomain: cluster.local.
hairpinMode: promiscuous-bridge
maxPods: 200
failSwapOn: false
imageGCHighThresholdPercent: 90
imageGCLowThresholdPercent: 80
imageMinimumGCAge: 5m0s
serializeImagePulls: false
authentication:
  x509:
    clientCAFile: /data/apps/kubernetes/pki/ca.pem
  anonymous:
    enbaled: false
  webhook:
    enbaled: false
EOF

# node2启动kubelet
# systemctl daemon-reload&&systemctl enable kubelet&&systemctl restart kubelet && systemctl status kubelet -l
# systemctl status kubelet
~~~

2. 配置 kube-proxy

kube-proxy 负责为 Service 提供 cluster 内部的服务发现和负载均衡；每台机器上都运行一个 kube-proxy 服务，它监听 API server 中 service和 endpoint 的变化情况，并通过 ipvs/iptables 等来为服务配置负载均衡（仅支持 TCP 和 UDP）。

注意：使用 ipvs 模式时，需要预先在每台 Node 上加载内核模块nf_conntrack_ipv4, ip_vs, ip_vs_rr, ip_vs_wrr, ip_vs_sh 等。

master节点上操作

~~~powershell
安装 conntrack-tools
# yum install -y conntrack-tools ipvsadm ipset conntrack libseccomp

创建服务启动文件
# cat > /usr/lib/systemd/system/kube-proxy.service << EOF
[Unit]
Description=Kubernetes Kube-Proxy Server
Documentation=https://github.com/kubernetes/kubernetes
After=network.target
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kube-proxy.conf
ExecStart=/data/apps/kubernetes/server/bin/kube-proxy \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBECONFIG \\
\$KUBE_PROXY_ARGS
Restart=on-failure
LimitNOFILE=65536
KillMode=process
[Install]
WantedBy=multi-user.target
EOF
~~~

启用 ipvs 主要就是把 kube-proxy 的--proxy-mode 配置选项修改为 ipvs,并且要启用--masquerade-all，使用 iptables 辅助 ipvs 运行。

~~~powershell
创建配置文件
# cat > /data/apps/kubernetes/etc/kube-proxy.conf << EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/kube-proxy/"
KUBECONFIG="--kubeconfig=/data/apps/kubernetes/etc/kube-proxy.kubeconfig"
KUBE_PROXY_ARGS="--proxy-mode=ipvs --masquerade-all=true --cluster-cidr=10.88.0.0/16"
EOF

# 启动 kube-proxy 并设置为开机自启动
# systemctl daemon-reload&&systemctl enable kube-proxy&&systemctl start kube-proxy
# systemctl status kube-proxy
~~~

在所有Node上操作

~~~powershell
安装 conntrack-tools
# yum install -y conntrack-tools ipvsadm ipset conntrack libseccomp

创建服务启动文件
# cat > /usr/lib/systemd/system/kube-proxy.service << EOF
[Unit]
Description=Kubernetes Kube-Proxy Server
Documentation=https://github.com/kubernetes/kubernetes
After=network.target
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kube-proxy.conf
ExecStart=/data/apps/kubernetes/node/bin/kube-proxy \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBECONFIG \\
\$KUBE_PROXY_ARGS
Restart=on-failure
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
EOF

创建配置文件
# cat > /data/apps/kubernetes/etc/kube-proxy.conf << EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/kube-proxy/"
KUBECONFIG="--kubeconfig=/data/apps/kubernetes/etc/kube-proxy.kubeconfig"
KUBE_PROXY_ARGS="--proxy-mode=ipvs --masquerade-all=true --cluster-cidr=10.88.0.0/16"
EOF

# 启动 kube-proxy 并设置为开机自启动
# systemctl daemon-reload&&systemctl enable kube-proxy&&systemctl start kube-proxy
# systemctl status kube-proxy


~~~

3.通过证书验证添加各个节点

~~~powershell
在 master 节点操作
[root@master etc]# kubectl get csr
NAME                                                   AGE   REQUESTOR           CONDITION
node-csr-5eGOzmAXliEO2uarHLkwlIT2fBgUAmUsxsI3SoY7hqc   18m   kubelet-bootstrap   Pending
node-csr-npkuftNKggSsORCKqhipwybQXrn7kpxCpb2SX1Gfbo4   18m   kubelet-bootstrap   Pending
node-csr-sWDUOicJsl2N-4BL8zWrXpQZs9xSiUKgsJ5-17sLUgQ   18m   kubelet-bootstrap   Pending

通过验证并添加进集群
[root@master etc]# kubectl get csr | awk '/node/{print $1}' | xargs kubectl certificate approve
certificatesigningrequest.certificates.k8s.io/node-csr-5eGOzmAXliEO2uarHLkwlIT2fBgUAmUsxsI3SoY7hqc approved
certificatesigningrequest.certificates.k8s.io/node-csr-npkuftNKggSsORCKqhipwybQXrn7kpxCpb2SX1Gfbo4 approved
certificatesigningrequest.certificates.k8s.io/node-csr-sWDUOicJsl2N-4BL8zWrXpQZs9xSiUKgsJ5-17sLUgQ approved


[root@192 apiserver]# kubectl get csr
NAME                                                   AGE       REQUESTOR             CONDITION
node-csr-HnWF5bl4hcOMlAneHU2owVAvVn7bBPHzXk4YTTDhTbQ   112m      kubelet-bootstrap     Approved,Issued
node-csr-IuRy0gVF7RMNqtAFoQxNQi_vJxwywsqufBgHQUJJ6us   112m      kubelet-bootstrap     Approved,Issued
node-csr-iY4shNnZuqPbQ-sZZ9BRAUyViwW_yHKj801xPWeAEL4   112m      kubelet-bootstrap     Approved,Issued


查看节点
[root@master etc]# kubectl get nodes 
NAME             STATUS   ROLES    AGE     VERSION
192.168.10.162   Ready    <none>   4m27s   v1.22.8
192.168.10.190   Ready    <none>   3m49s   v1.22.8
192.168.10.191   Ready    <none>   3m25s   v1.22.8


设置集群角色
# kubectl label nodes 192.168.10.162 node-role.kubernetes.io/master=MASTER-1
# kubectl label nodes 192.168.10.190 node-role.kubernetes.io/node=NODE-1
# kubectl label nodes 192.168.10.191 node-role.kubernetes.io/node=NODE-2

设置 master 一般情况下不接受负载
kubectl taint nodes 192.168.10.162 node-role.kubernetes.io/master=MASTER-1:NoSchedule --overwrite

此时查看节点 Roles, ROLES 已经标识出了 master 和 node
NAME             STATUS   ROLES    AGE   VERSION
192.168.10.162   Ready    master   21m   v1.22.8
192.168.10.190   Ready    node     20m   v1.22.8
192.168.10.191   Ready    node     19m   v1.22.8

~~~

4. 配置网络插件

Master 和 node 节点

~~~powershell
# cd /mnt/nfs_mnt/nfs_a/k8s-install/software/
# wget https://github.com/flannel-io/flannel/releases/download/v0.17.0/flannel-v0.17.0-linux-amd64.tar.gz
# cp /mnt/nfs_mnt/nfs_a/k8s-install/software/flannel-v0.17.0-linux-amd64.tar.gz /root/
# tar zxvf flannel-v0.17.0-linux-amd64.tar.gz
# mv flanneld mk-docker-opts.sh /data/apps/kubernetes/server/bin/
# chmod +x /data/apps/kubernetes/server/bin/*

node节点
# mv flanneld mk-docker-opts.sh /data/apps/kubernetes/node/bin/
# chmod +x /data/apps/kubernetes/node/bin/*
~~~

4.1 创建 flanneld.conf 配置文件

创建网络段

~~~powershell
#在 etcd 集群执行如下命令， 为 docker 创建互联网段 etcd 需要开启 --enable_v2 启用v2版本api,同时设置网络时候需要用v2版本 只需一个机器执行
# ETCDCTL_API=2 /data/apps/etcd/bin/etcdctl --ca-file=/data/apps/etcd/ssl/etcd-ca.pem --cert-file=/data/apps/etcd/ssl/etcd.pem --key-file=/data/apps/etcd/ssl/etcd-key.pem --endpoints="https://192.168.10.162:2379,https://192.168.10.190:2379,https://192.168.10.191:2379" set /coreos.com/network/config '{"Network":"10.88.0.0/16","Backend": {"Type":"vxlan"}}'

# /data/apps/etcd/bin/etcdctl --cacert=/data/apps/etcd/ssl/etcd-ca.pem 
# --cert=/data/apps/etcd/ssl/etcd.pem --key=/data/apps/etcd/ssl/etcd-key.pem 
# --endpoints="https://192.168.10.162:2379,https://192.168.10.190:2379,https://192.168.10.191:2379" 
# put /coreos.com/network/config '{"Network":"10.88.0.0/16","Backend": {"Type":"vxlan"}}'
~~~

在 node 节点创建 etcd 证书存放路径， 并拷贝 etcd 证书到 Node 节点，

~~~powershell
注意：我这里node节点也是etcd节点，所有可以省略
# mkdir -p /data/apps/etcd
# scp -r /data/apps/etcd/ssl 192.168.10.190:/data/apps/etcd/
# scp -r /data/apps/etcd/ssl 192.168.10.191:/data/apps/etcd/
~~~

创建 flannel 配置文件 
使用ectd v2的参数格式

~~~powershell
# cat > /data/apps/kubernetes/etc/flanneld.conf << EOF
FLANNEL_OPTIONS="--etcd-prefix=/coreos.com/network --etcd-endpoints=https://192.168.10.162:2379,https://192.168.10.190:2379,https://192.168.10.191:2379 --etcd-cafile=/data/apps/etcd/ssl/etcd-ca.pem --etcd-certfile=/data/apps/etcd/ssl/etcd.pem --etcd-keyfile=/data/apps/etcd/ssl/etcd-key.pem"
EOF
~~~

4.2 创建系统服务

~~~powershell
# cat > /usr/lib/systemd/system/flanneld.service << EOF
[Unit]
Description=Flanneld overlay address etcd agent
After=network-online.target network.target
Before=docker.service
[Service]
Type=notify
EnvironmentFile=/data/apps/kubernetes/etc/flanneld.conf
ExecStart=/data/apps/kubernetes/server/bin/flanneld --ip-masq \$FLANNEL_OPTIONS
ExecStartPost=/data/apps/kubernetes/server/bin/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/subnet.env
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF


# 以下操作不需要执行，在启动flanneld时候，会创建该文件
mkdir -p /run/flannel/
cat > /run/flannel/subnet.env << EOF
DOCKER_OPT_BIP="--bip=10.88.32.1/24"
DOCKER_OPT_IPMASQ="--ip-masq=false"
DOCKER_OPT_MTU="--mtu=1450"
DOCKER_NETWORK_OPTIONS=" --bip=10.88.32.1/24 --ip-masq=false --mtu=1450"
EOF
~~~

注意： master 节点的 flanneld 服务配置文件 /node/bin/ 需要改为/server/bin/

4.3 修改 docker.service 启动文件

添加子网配置文件

~~~powershell
# vim /usr/lib/systemd/system/docker.service
# --graph 表示修改 docker 默认/var/lib/docker 存储路径为/data/docker , 需提前创建目录
EnvironmentFile=/run/flannel/subnet.env
ExecStart=/usr/bin/dockerd -H unix:// $DOCKER_NETWORK_OPTIONS $DOCKER_DNS_OPTIONS
~~~

修改 docker 服务启动文件，注入 dns 参数

~~~powershell
# mkdir -p /usr/lib/systemd/system/docker.service.d/
# cat > /usr/lib/systemd/system/docker.service.d/docker-dns.conf << EOF
[Service]
Environment="DOCKER_DNS_OPTIONS=--dns 100.100.2.136 --dns 100.100.2.138 --dns-search default.svc.cluster.local --dns-search svc.cluster.local --dns-search default.svc.lgh.work --dns-search svc.lgh.work --dns-opt ndots:2 --dns-opt timeout:2 --dns-opt attempts:2"
EOF
~~~

4.4 启动 flanneld

~~~powershell
# systemctl daemon-reload
# systemctl start flanneld
# systemctl restart docker
# systemctl status flanneld
~~~

5.配置 coredns(master节点上操作)

~~~powershell
# 10.99.0.2 是 kubelet 中配置的 dns
# 安装 coredns
# cd /root && mkdir coredns && cd coredns
# wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed
# wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/deploy.sh
# chmod +x deploy.sh

# ./deploy.sh -s -r 10.99.0.0/16 -i 10.99.0.2 -d cluster.local > coredns.yml
# kubectl apply -f coredns.yml

#查看 coredns 是否运行正常
# kubectl get svc,pods -n kube-system
~~~



6.配置dashboard(master节点上操作)

~~~powershell
cd /root && mkdir dashboard && cd dashboard
curl -O https://soft.8090st.com/kubernetes/dashboard/kubernetes-dashboard.yaml

生成证书
openssl genrsa -des3 -passout pass:x -out dashboard.pass.key 2048
openssl rsa -passin pass:x -in dashboard.pass.key -out dashboard.key
rm dashboard.pass.key -rf
openssl req -new -key dashboard.key -out dashboard.csr
...
...
openssl x509 -req -sha256 -days 365 -in dashboard.csr -signkey dashboard.key -out dashboard.crt

将创建的证书拷贝到其他 node 节点
修改kubernetes-dashboard.yaml文件
1.修改证书挂载方式
volumes:
- name: kubernetes-dashboard-certs
# secret:
# secretName: kubernetes-dashboard-certs
hostPath:
path: /data/apps/kubernetes/certs
type: Directory
2.修改service,端口映射到node上
...
spec:
  type: NodePort
  ports:
    - port: 443
      targetPort: 8443
      nodePort: 31000
  selector:
    k8s-app: kubernetes-dashboard


# kubectl apply -f kubernetes-dashboard.yaml

~~~

配置dashboard令牌

~~~powershell
# cat > token.sh << EOF
#!/bin/bash
if kubectl get sa dashboard-admin -n kube-system &> /dev/null;then
echo -e "\033[33mWARNING: ServiceAccount dashboard-admin exist!\033[0m"
else
kubectl create sa dashboard-admin -n kube-system
kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin
fi
EOF

# sh token.sh #生成登录令牌

获取token令牌
kubectl describe secret -n kube-system $(kubectl get secrets -n kube-system | grep dashboard-admin | cut -f1 -d ' ') | grep -E '^token' > login.token

~~~

登录dashboard

~~~powershell
通过 node 节点 ip+端口号访问
# kubectl get svc,pods -n kube-system -o wide
NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE   SELECTOR
service/kube-dns               ClusterIP   10.99.110.110   <none>        53/UDP,53/TCP,9153/TCP   46h   k8s-app=kube-dns
service/kubernetes-dashboard   NodePort    10.99.129.167   <none>        443:31000/TCP            45h   k8s-app=kubernetes-dashboard

NAME                                       READY   STATUS    RESTARTS   AGE   IP           NODE           NOMINATED NODE   READINESS GATES
pod/coredns-6dcff984f9-gflpx               1/1     Running   1          42h   10.99.24.2   192.168.0.21   <none>           <none>
pod/kubernetes-dashboard-6c87554b5-cf7nt   1/1     Running   0          29h   10.99.86.2   192.168.0.22   <none>           <none>

这里我们可以看到dashboard的pod被调度到192.168.0.22节点上，service对应的nodePort为31000
所以访问链接为：https://192.168.0.22:31000


~~~

